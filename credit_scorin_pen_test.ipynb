{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "committed-plasma",
   "metadata": {},
   "source": [
    "# Проект SF Scoring - построение модели банковского скоринга.\n",
    "Автор - Пальванова Юлия. Версия 1, от 3 марта 2021\n",
    "\n",
    "# 0. Введение.\n",
    "В этом проекте рассматривается задача банковского скоринга - принятие решения о том, будет ли заёмщик проблемным (т.е. допустит дефолт по кредиту) или нет. Решение принимается по набору различных признаков для каждого клиента, таких как наличие машины, загранпаспорта, доходы, и прочие. Для принятия решений о новых клиентах используется модель, обученная на исторических данных о нескольких десятках тысяч клиентов, о которых известно, были ли они проблемными или нет. Таким образом, задача является бинарной классификацией, и может быть решена различными методами: логистической регрессией, методом опорных векторов, различными методами решающих деревьев, и простыми методами классификации (наивный байесовский классификатор и kNN). Основной метрикой соревнования на kaggle является ROC AUC Score, хотя также будут проанализированы и другие метрики классификации (confusion matrix, accuracy, precision, recall, F1 score).\n",
    "\n",
    "# Cодержание.\n",
    "1) Анализ данных.\n",
    "\n",
    "2) Отбор и трансформация признаков\n",
    "\n",
    "3) Применение простейших моделей - наивный Байес и kNN, валидация и подбор гиперпараметров.\n",
    "\n",
    "4) Применение линейных моделей логистической регрессии и метода опорных векторов, валидация, подбор гиперпараметров.\n",
    "\n",
    "5) Применение XGBoost, валидация и подбор гиперпараметров.\n",
    "\n",
    "6) Сравнение метрик, выводы.\n",
    "\n",
    "# 1. EDA.\n",
    "Датасет уже очень хорошо подготовлен. Для упрощения EDA будем использовать модуль dataprep.eda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    " This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U dataprep\n",
    "!pip install xgboost\n",
    "!pip install catboost\n",
    "#import dataprep.eda\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, FunctionTransformer, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_selection import f_classif,mutual_info_classif, SelectKBest, SelectFromModel\n",
    "from sklearn.metrics import (plot_confusion_matrix, plot_roc_curve, f1_score, confusion_matrix, \n",
    "                             precision_score, precision_recall_curve, accuracy_score, recall_score, \n",
    "                             plot_precision_recall_curve, roc_auc_score)\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn import set_config\n",
    "import xgboost as xgb\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "set_config(display='diagram')\n",
    "\n",
    "\n",
    "from pandas import Series\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "\n",
    "import warnings\n",
    "from dateutil import parser\n",
    "import dateutil\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "import plotly as px\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "\n",
    "from statistics import variance\n",
    "# импорт дробей как значений параметров\n",
    "from fractions import Fraction as fr\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 50)  # показывать больше строк\n",
    "pd.set_option('display.max_columns', 50)  # показывать больше колонок\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xml.etree.ElementTree as ET \n",
    "#!pip install xmljson\n",
    "#import xmljson\n",
    "import pickle  \n",
    "from datetime import datetime  \n",
    "from os import path  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import json  \n",
    "from pprint import pprint  \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "#подгрузка данных\n",
    "train = pd.read_csv('train.csv')\n",
    "test= pd.read_csv('test.csv')\n",
    "sample_sub = pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-object",
   "metadata": {},
   "source": [
    "# 1.Анализ данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns, test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-greek",
   "metadata": {},
   "source": [
    "### Описания полей - копипаста предоставленного описания.\n",
    "\n",
    "- client_id - идентификатор клиента\n",
    "- education - уровень образования\n",
    "- sex - пол заемщика\n",
    "- age - возраст заемщика\n",
    "- car - флаг наличия автомобиля\n",
    "- car_type - флаг автомобиля иномарки\n",
    "- mdecline_app_cnt - количество отказанных прошлых заявок\n",
    "- good_work - флаг наличия “хорошей” работы\n",
    "- bki_request_cnt - количество запросов в БКИ\n",
    "- home_address - категоризатор домашнего адреса\n",
    "- work_address - категоризатор рабочего адреса\n",
    "- income - доход заемщика\n",
    "- foreign_passport - наличие загранпаспорта\n",
    "- sna - связь заемщика с клиентами банка\n",
    "- first_time - давность наличия информации о заемщике\n",
    "- score_bki - скоринговый балл по данным из БКИ\n",
    "- region_rating - рейтинг региона\n",
    "- app_date - дата подачи заявки\n",
    "- default - флаг дефолта по кредиту\n",
    "\n",
    "Первым делом посмотрим пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum(), test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-custody",
   "metadata": {},
   "source": [
    "Для наглядности посмотрим признак education на графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['education'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['education'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-registrar",
   "metadata": {},
   "source": [
    "Пропущенные значения есть только в столбце education. Заполним эти пропуски модой. Для того, чтобы избежать даже минимальной утечки данных из трейна в тест, заполнение пропусков в тесте надо проводить тем же значением, что и в трейне (то есть не считать моду по тесту, а взять её из трейна). И вообще, все шаги подготовки данных производятся на трейне, а применяются потом к тесту\\валидации. Поэтому будем готовить pipeline, чтобы гарантировать отсутствие утечек данных. Для подготовки столбцов, которые у нас весьма разнородные, будем использовать ColumnTransfromer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "mport collections\n",
    "\n",
    "c_1 = collections.Counter(train['education'])\n",
    "c_2 = collections.Counter(test['education'])\n",
    "\n",
    "train['education'].fillna(c_1.most_common()[0][0], inplace=True)\n",
    "test['education'].fillna(c_2.most_common()[0][0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-faith",
   "metadata": {},
   "source": [
    "Проверим успешность заполнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum(), test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['education'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['education'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-michael",
   "metadata": {},
   "source": [
    "Для удобного анализа сгруппируем признаки в три категории по типу их обработки (категориальные, бинарные и числовые)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# бинарные переменные\n",
    "ord_cols=['region_rating', 'first_time']\n",
    "# котегориальные переменные\n",
    "cat_cols=['sex', 'car', 'car_type','foreign_passport', 'work_address', 'home_address', 'sna', 'education']\n",
    "# числовые переменные\n",
    "num_cols=['decline_app_cnt', 'bki_request_cnt', 'income', 'age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-genre",
   "metadata": {},
   "source": [
    "Посмотрим на распределение числовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-color",
   "metadata": {},
   "source": [
    "Построим графики распределения логарифмированных переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_cols:\n",
    "    plt.figure()\n",
    "    sns.distplot(train[i][train[i] > 0].dropna(), kde = False, rug=False)\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-madrid",
   "metadata": {},
   "source": [
    "Все признаки имеют смещение к левому краю.\n",
    "\n",
    "Построим boxplot’ы для численных переменных и посмотрим их распределение по отношение к целевой переменной default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "!pip install plotnine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-affiliate",
   "metadata": {},
   "source": [
    "### Возраст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='default',\n",
    "            y='age',\n",
    "            kind='boxen',\n",
    "            data=train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-alpha",
   "metadata": {},
   "source": [
    "Количество отказанных прошлых заявок¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='default',\n",
    "            y='decline_app_cnt',\n",
    "            kind='boxen',\n",
    "            data=train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-sheep",
   "metadata": {},
   "source": [
    "### Количество запросов БКИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='default',\n",
    "            y='bki_request_cnt',\n",
    "            kind='boxen',\n",
    "            data=train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-pharmacology",
   "metadata": {},
   "source": [
    "### Доход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='default',\n",
    "            y='income',\n",
    "            kind='boxen',\n",
    "            data=train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-swaziland",
   "metadata": {},
   "source": [
    "### Вывод по количественным признакам.\n",
    "Выбросы есть во всех количественных признаках. Но они не кажутся неадекватными, и их доля очень невелика. Поэтому исправлять мы их не будем.\n",
    "\n",
    "### Корреляция¶\n",
    "Посмотрим на корреляцию признаков в тестовой и основной выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1)\n",
    "plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(test.corr(), square=True,\n",
    "              annot=True, fmt=\".1f\", linewidths=0.1, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-regression",
   "metadata": {},
   "source": [
    "Смотрим, у каких пар признаков сильная взаимосвязь:\n",
    "\n",
    "Домашний адрес и адрес работы. Довольно логично, так как в основном люди живут и работают в одном населенном пункте.\n",
    "Связь заемщика с клиентами банка и давность наличия информации о заемщике. Тоже в полеъне логично\n",
    "Теперь посмотрим кореляцию признаков на файле трейн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1)\n",
    "plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(train.corr(), square=True,\n",
    "              annot=True, fmt=\".1f\", linewidths=0.1, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-journalist",
   "metadata": {},
   "source": [
    "Картина с корреляцией признаков аналогичная. При этом, большой корреляции с целевой переменной нет ни у дного признака. Максимальная корреляция с коэффициентом 0.2 наблюдается только целевой переменной со скоринговым баллом по данным из БКИ\n",
    "\n",
    "С моделью в общем все ясно. Теперь поработаем над данными.\n",
    "\n",
    "# 2. Отбор и трансформация признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "#загоним app_date в формат unix timestamp\n",
    "train_for_selection = train.drop(columns = ['client_id', 'default'])\n",
    "train_for_selection['app_date'] = train_for_selection['app_date'].apply(lambda x: pd.to_datetime(x).timestamp())\n",
    "train_for_selection['education'].fillna(train_for_selection.education.mode(), inplace = True)\n",
    "train_for_selection = pd.get_dummies(train_for_selection, columns=cat_cols+ord_cols)\n",
    "\n",
    "train_for_selection.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-alaska",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "pd.Series(\n",
    "    dict(zip(train_for_selection.columns, \n",
    "             f_classif(train_for_selection, train['default'])[0])))\\\n",
    "    .sort_values().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-framework",
   "metadata": {},
   "source": [
    "### Mutual inforamtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "pd.Series(dict(\n",
    "    zip(\n",
    "        train_for_selection.columns, \n",
    "                   mutual_info_classif(train_for_selection, train['default']))))\\\n",
    "                   .sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-spirit",
   "metadata": {},
   "source": [
    "### Вывод.\n",
    "Мало влияющие на результат признаки есть. Для линейных методов цели снизить размерность пространства категориальных признаков не стоит, потому что и так всё работает быстро. Для SVM при применении kernel trick вычисления становятся довольно длительными, поэтому будем пробовать отбирать признаки.\n",
    "\n",
    "Итого, вот что мы делаем с признаками в \"базовом\" варианте:\n",
    "- client_id - идентификатор клиента. Для модели он не нужен. Трогать его не будем, понадобится исключительно для соотнесения предикта с истинным значением на тесте и валидации.\n",
    "- education - уровень образования, категориальный признак, применим к нему OneHotEncoder.\n",
    "- sex - пол заемщика - бинарный категориальный признак, применим к нему OneHotEncoder, который в данном случае выдаст ровно один признак.\n",
    "- age - возраст заемщика - количественный признак. Правый хвост довольно тяжёлый, распределение похоже на логнормальное. Возьмём логарифм, применим StandardScaler.\n",
    "- car - флаг наличия автомобиля - категоральный бинарный, OneHotEncoder\n",
    "- car_type - флаг автомобиля иномарки - категоральный бинарный, OneHotEncoder\n",
    "- decline_app_cnt - количество отказанных прошлых заявок - количественный признак, больше всего вообще напоминает экспоненциальное распределение. Прибавим единицу и возьмём логарифм.\n",
    "- good_work - флаг наличия “хорошей” работы - бинарный, можно вообще не трогать\n",
    "- bki_request_cnt - количество запросов в БКИ - аналогично decline_app_cnt\n",
    "- home_address - категоризатор домашнего адреса. Вообще не до конца понятно, что это значит. Тут 3 категории (не понятно о чем каждая из категорий говорит). Непонятно, есть ли тут отношение порядка. Попробуем просто перекодировать в dummies.\n",
    "- work_address - категоризатор рабочего адреса - аналогично предыдущему\n",
    "- income - доход заемщика - количественный признак, с тяжёлым хвостом. Логарифм, StandardScaler\n",
    "- foreign_passport - наличие загранпаспорта, бинарный категориальный признак, onehotencoder\n",
    "- sna - связь заемщика с клиентами банка, абсолютно непонятно значение этого признака. Будем пока считать категориальным и применим onehotencoder\n",
    "- first_time - давность наличия информации о заемщике. Природа её, возможно и числовая, но тут всего 4 значения. Опять же напрашивается onehotencoder.\n",
    "- score_bki - скоринговый балл по данным из БКИ, количественная, кравсивое нормальное распределение, применим standard scaler.\n",
    "- region_rating - рейтинг региона. Опять же, имеет числовую природу, но всего 4 значения - растаскиваем на dummies.\n",
    "- app_date - дата подачи заявки - сама по себе бесполезна, но можно повытягивать дополнительные признаки.\n",
    "- default - флаг дефолта по кредиту - целевая переменная, не трогаем.\n",
    "\n",
    "Попробуем получить дополнительные признаки из даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-morocco",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_features = train.copy()\n",
    "train_for_features['app_date'] = train_for_features['app_date'].apply(pd.to_datetime)\n",
    "print(train_for_features['app_date'].dt.year.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-scotland",
   "metadata": {},
   "source": [
    "Год сразу выбрасываем. Возможные признаки: месяц, число, день недели, выходной или нет. При этом маловероятно, что голое число хоть с чем-то будет коррелировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_features['month'] = train_for_features['app_date'].dt.month\n",
    "train_for_features['day'] = train_for_features['app_date'].dt.day\n",
    "train_for_features['weekday'] = train_for_features['app_date'].dt.weekday\n",
    "train_for_features['is_weekend'] = train_for_features['weekday'].apply(lambda x: 1 if x in (5,6) else 0)\n",
    "\n",
    "train_for_features.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1)\n",
    "plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(train_for_features.corr(), square=True,\n",
    "              annot=True, fmt=\".1f\", linewidths=0.1, cmap=\"RdBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-thesaurus",
   "metadata": {},
   "source": [
    "Полученные признаки никак не коррелируют с целевой переменной. Зато, очевидно, день недели коррелирует с признаком \"выходной\". Не будем пользоваться последним признаком. Лучше потом weekday растащим на dummy-переменные. И признак \"число\" выкинем, он кажется бесполезным. Напишем класс для генерации новых признаков, со стандартным интерфейсом sklearn, чтобы потом его можно было встроить в модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateFeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_col):\n",
    "        self.date_col = date_col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        dates = pd.to_datetime(X[self.date_col])\n",
    "        ts = dates.apply(lambda x: x.timestamp()).values.reshape(-1,1)\n",
    "        weekdays = dates.dt.weekday.values.reshape(-1,1)\n",
    "        months = dates.dt.month.values.reshape(-1,1)\n",
    "        scl = MinMaxScaler()\n",
    "        ohe = OneHotEncoder(sparse = False)\n",
    "        return np.hstack((ohe.fit_transform(weekdays), scl.fit_transform(ts), ohe.fit_transform(months)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-denial",
   "metadata": {},
   "source": [
    "Распределим признаки по категориям, и напишем код для обработки образования - onehotencoder и числовых переменных, требующих логарифмирования и нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['sex', 'car', 'car_type','foreign_passport', 'work_address', 'home_address', 'sna']\n",
    "num_features = ['decline_app_cnt', 'bki_request_cnt', 'income', 'age']\n",
    "ord_features = ['region_rating', 'first_time']\n",
    "features_to_leave_untouched = ['good_work']\n",
    "edu_transform_pipe = OneHotEncoder(sparse=False) # код для обработки образования\n",
    "#make_pipeline(SimpleImputer(strategy='most_frequent'), \n",
    "numeric_transformer = make_pipeline(FunctionTransformer(func = np.log1p), StandardScaler()) #код для всех количсественных\n",
    "remaining_cols = set(train.columns) - set(cat_features)- set(num_features)- set(ord_features) - set(['education']) - set(features_to_leave_untouched)\n",
    "print(remaining_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-original",
   "metadata": {},
   "source": [
    "Теперь напишем самый главный код по обработке всеx признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoder = make_column_transformer(\n",
    "    (FunctionTransformer(func = lambda x: x), features_to_leave_untouched),  #костыль, чтобы не мучиться с remainder и не вытаскивать из него app_date\n",
    "    (edu_transform_pipe, ['education']),\n",
    "    (OneHotEncoder(drop='if_binary', sparse=False), cat_features+ord_features),\n",
    ")\n",
    "num_transformer = make_column_transformer(\n",
    "    (numeric_transformer, num_features),\n",
    "    (StandardScaler(), ['score_bki'])\n",
    ")\n",
    "poly_num_transformer = make_pipeline(num_transformer, PolynomialFeatures(degree=2))\n",
    "\n",
    "# Делаем матрицу плана\n",
    "total_features = FeatureUnion([('gen', DateFeatureGenerator(date_col = 'app_date')),\n",
    "                               ('encode', features_encoder),\n",
    "                               ('trans_num', num_transformer)\n",
    "                                ])\n",
    "total_features.fit(train.drop(columns = ['default', 'client_id']))\n",
    "train_features = total_features.transform(train.drop(columns = ['default', 'client_id']))\n",
    "test_features = total_features.transform(test.drop(columns = ['client_id']))\n",
    "\n",
    "\n",
    "poly_total_features = FeatureUnion([('gen', DateFeatureGenerator(date_col = 'app_date')),\n",
    "                               ('encode', features_encoder),\n",
    "                               ('trans_num_poly', poly_num_transformer)\n",
    "                                ])\n",
    "poly_total_features.fit(train.drop(columns = ['default', 'client_id']))\n",
    "poly_train_features = poly_total_features.transform(train.drop(columns = ['default', 'client_id']))\n",
    "poly_test_features = poly_total_features.transform(test.drop(columns = ['client_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-possession",
   "metadata": {},
   "source": [
    "К сожалению, при обработке не удалось сохранить имена столбцов (потому что на выходе получаем массив numpy). Будем работать с чем есть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train['default'], random_state=42, test_size=0.2)\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(poly_train_features, train['default'], random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-perth",
   "metadata": {},
   "source": [
    "# 3.Простые модели.\n",
    "## 3.1. Naive Bayes.\n",
    "При применении наивного байесовского классификатора сразу нужно держать в голове, что его \"наивное\" предположение о независимости признаков у нас, скорее всего не выполнится. Поэтому сначала попробуем запустить его на полной матрице плана, а потом на топ-10, 20, 30 и 40 признаках по ANOVA, как раз отсечём скоррелированные друг с другом признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_metrics(name, clf, X, y_true):\n",
    "    y_pred = clf.predict(X)\n",
    "    y_proba = clf.predict_proba(X)[:,1]\n",
    "    results = pd.DataFrame(\n",
    "         {\n",
    "            'Classifier': str(clf),\n",
    "            'Accuracy': accuracy_score(y_true, y_pred),\n",
    "            'Precision': precision_score(y_true, y_pred),\n",
    "            'Recall': recall_score(y_true, y_pred),\n",
    "            'F1': f1_score(y_true, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_true, y_proba)\n",
    "         }, index = [name])\n",
    "    plot_confusion_matrix(clf, X, y_true.values.reshape(-1,1))\n",
    "    plot_roc_curve(clf, X, y_true.values.reshape(-1,1))\n",
    "    plot_precision_recall_curve(clf, X, y_true.values.reshape(-1,1))\n",
    "    return results\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "results = construct_metrics('Gauss NB without feature selection', gnb, X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-flush",
   "metadata": {},
   "source": [
    "Получилось что получилось. Мы ввели второе допущение по поводу нормального распределения признаков. Получили много ошибок, (первого рода, если нулевая гипотеза у нас о том, что клиент дефолтный), или False-Positive(если считать positive = клиент недефолтный). Посмотрим что с отсечением признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_with_selection = make_pipeline(SelectKBest(), GaussianNB())\n",
    "param_grid = {\n",
    "    'selectkbest__k':[10,20,30,37]\n",
    "    }\n",
    "gridsearch = GridSearchCV(nb_with_selection, param_grid, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.fit(X_train, y_train)\n",
    "model = gridsearch.best_estimator_\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(construct_metrics('Gauss NB with 36 features selected', model, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-venice",
   "metadata": {},
   "source": [
    "Ничего не поменялось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_p, y_train_p)\n",
    "results = results.append(construct_metrics('Gauss NB poly_features', gnb, X_test_p, y_test_p))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-behalf",
   "metadata": {},
   "source": [
    "Полиномиальные признаки так же рне дали хорошего результата\n",
    "\n",
    "## 3.2. K ближайших соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "results = results.append(construct_metrics('KNN, default parameters', knn, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-insulin",
   "metadata": {},
   "source": [
    "Дно, попробуем оптимизировать гиперпараметры. А с полиномиальными признакими ничего не будем делать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_neighbors': range(1,6,1), \n",
    "     'weights': ['uniform', 'distance'], \n",
    "     'p':[1, 2]\n",
    "    }\n",
    "] # остальные гиперпараметры не до конца понятны, а расчёты занимают какое-то время, поэтому лезть туда не стану\n",
    "gridsearch = GridSearchCV(knn, param_grid, scoring='f1', n_jobs=-1)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "model = gridsearch.best_estimator_\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(construct_metrics('KNN, 1 nearest neighbor', model, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-portsmouth",
   "metadata": {},
   "source": [
    "KNN сработал слабо. С учётом большого количества категориальных признаков это неудивительно.\n",
    "\n",
    "# 4. Логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала параметры по умолчанию, только дадим побольше итераций.\n",
    "logreg = LogisticRegression(max_iter = 10000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "results = results.append(construct_metrics('Logistic regression, default parameters', logreg, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-sharp",
   "metadata": {},
   "source": [
    "ROC AUC-удовлетворительные, а вот с recall проблема, он вообще никакой. Если оторваться от целевой метрики ROC AUC, то это значит что мы очень плохо отсеиваем дефолтных клиентов. А всё потому, что классы несбалансированы - недефолтных клиентов гораздо больше, чем дефолтных. Поэтому все дальнейшие модели будем запускать с class_weight='balanced'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-institute",
   "metadata": {},
   "source": [
    "Веса в регрессии не взорвались, всё в порядке. Видно, что какие-то признаки получают довольно большие коэффициенты, какие-то - близкие к нулю.\n",
    "\n",
    "Попробуем сбалансировать классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter = 10000, random_state=42, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "results = results.append(construct_metrics('Logistic regression, default parameters, balanced classes', logreg, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-element",
   "metadata": {},
   "source": [
    "Так recall у нас улучшился, но зато теперь мы допускаем больше ошибок второго рода (считаем недефолтных клиентов дефолтными). Попробуем полиномиальные признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter = 10000, random_state=42,class_weight='balanced')\n",
    "logreg.fit(X_train_p, y_train_p)\n",
    "y_pred = logreg.predict(X_test_p)\n",
    "results = results.append(construct_metrics('Logistic regression, default parameters w\\poly features', logreg, X_test_p, y_test_p))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-bulgaria",
   "metadata": {},
   "source": [
    "Огромных качественных изменений не получилось. Попробуем оптимизировать параметры на оба случая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegressionCV(\n",
    "    Cs = np.linspace(0.2,2,10),\n",
    "    penalty = 'l2',\n",
    "    scoring = 'f1',\n",
    "    max_iter = 10000, \n",
    "    random_state=42, \n",
    "    class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "results = results.append(construct_metrics('Logistic regression, optimized C for L2',logreg, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegressionCV(\n",
    "    Cs = np.linspace(0.2,2,10),\n",
    "    penalty = 'l1',\n",
    "    scoring = 'f1',\n",
    "    solver = 'saga',\n",
    "    max_iter = 10000, \n",
    "    random_state=42, \n",
    "    class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "results = results.append(construct_metrics('Logistic regression, optimized C for L1',logreg, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_elastic = LogisticRegressionCV(\n",
    "    Cs = np.linspace(0.2,2,10),\n",
    "    penalty = 'elasticnet',\n",
    "    l1_ratios = np.linspace(0,1,6),\n",
    "    scoring = 'f1',\n",
    "    solver = 'saga',\n",
    "    max_iter = 10000, \n",
    "    random_state=42, \n",
    "    class_weight='balanced')\n",
    "logreg_elastic.fit(X_train, y_train)\n",
    "results = results.append(construct_metrics('Logistic regression, optimized C and L1_ratio for elasticnet',logreg_elastic, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-column",
   "metadata": {},
   "source": [
    "Регуляризация по L1 и L2 нормам выдаёт результат незначительно лучше.\n",
    "\n",
    "Посмотрим полиномиальные признаки для регуляризации elasticnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegressionCV(\n",
    "    Cs = np.linspace(0.4,1,4),\n",
    "    penalty = 'elasticnet',\n",
    "    l1_ratios = np.linspace(0,1,4),\n",
    "    scoring = 'f1',\n",
    "    solver = 'saga',\n",
    "    max_iter=10000, \n",
    "    tol = 0.001, #чтобы быстрее считалось\n",
    "    random_state=42, \n",
    "    class_weight='balanced')\n",
    "logreg.fit(X_train_p, y_train_p)\n",
    "results = results.append(construct_metrics('Logreg with poly features optimized', logreg, X_test_p, y_test_p))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-outside",
   "metadata": {},
   "source": [
    "Итого, лучший результат по ROC AUC получается при использовании регуляризации elasticnet без полиномиальных признаков. Параметры регуляризации такие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'C = {logreg_elastic.C_[0]}, l1_ratio = {logreg_elastic.l1_ratio_[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-clothing",
   "metadata": {},
   "source": [
    "Проведём кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logreg = LogisticRegression(\n",
    "        C = 0.2,\n",
    "        penalty = 'elasticnet',\n",
    "        l1_ratio = 0.8,\n",
    "        solver = 'saga',\n",
    "        max_iter=10000, \n",
    "        tol = 0.001, #чтобы быстрее считалось\n",
    "        random_state=42, \n",
    "        class_weight='balanced')\n",
    "cvsplitter = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "cross_validate(best_logreg, X_train, y_train, \n",
    "               scoring=('recall', 'f1', 'roc_auc'), cv = cvsplitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-jungle",
   "metadata": {},
   "source": [
    "Модель немного переобучается - метрики на кросс-валидации похуже.\n",
    "\n",
    "Обучим модель на полном трейне и сделаем файл для сабмита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logreg.fit(train_features,train['default'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'client_id':test.client_id.values, 'default':best_logreg.predict_proba(test_features)[:,1]}).to_csv('submission_best_logreg.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-legislation",
   "metadata": {},
   "source": [
    "# 5. Метод опорных векторов.\n",
    "Начнём с линейного SVC. В SVC нет метода predict_proba (потому что там нет вероятностей, есть только margin), вместо него decision function, поэтому перепишем метод для метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_metrics_svc(name, clf, X, y_true):\n",
    "    y_pred = clf.predict(X)\n",
    "    y_proba = clf.decision_function(X)\n",
    "    results = pd.DataFrame({\n",
    "            'Classifier': str(clf),\n",
    "            'Accuracy': accuracy_score(y_true, y_pred),\n",
    "            'Precision': precision_score(y_true, y_pred),\n",
    "            'Recall': recall_score(y_true, y_pred),\n",
    "            'F1': f1_score(y_true, y_pred),\n",
    "            'ROC AUC': roc_auc_score(y_true, y_proba)\n",
    "         }, index = [name])\n",
    "    plot_confusion_matrix(clf, X, y_true.values.reshape(-1,1))\n",
    "    plot_roc_curve(clf, X, y_true.values.reshape(-1,1))\n",
    "    plot_precision_recall_curve(clf, X, y_true.values.reshape(-1,1))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "svmclf = LinearSVC(class_weight='balanced', max_iter=10000)\n",
    "svmclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(construct_metrics_svc('LinearSVC',svmclf, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-reminder",
   "metadata": {},
   "source": [
    "Кросс-валидация и подбор гиперпараметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'C': np.linspace(0.2,2,5),\n",
    "    'max_iter':[10000]\n",
    "}\n",
    "cv = GridSearchCV(svmclf, params, scoring = 'f1', cv=5, n_jobs = 8)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(construct_metrics_svc('Linear SVC optimized',cv, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-gardening",
   "metadata": {},
   "source": [
    "Попробуем kernel trick, со стандартным ядром radial basis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_svc = SVC(class_weight='balanced', max_iter=-1)\n",
    "kernel_svc.fit(X_train, y_train)\n",
    "results = results.append(construct_metrics_svc('SVC with kernel trick', kernel_svc, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-amateur",
   "metadata": {},
   "source": [
    "Очень медленно. Боюсь, что не до кросс-валидации. Обучим на всём трейне линейный SVC и сделаем файл для сабмита."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(train_features,train['default'].values)\n",
    "pd.DataFrame({'client_id':test.client_id.values, \n",
    "              'default':cv.decision_function(test_features)})\\\n",
    "              .to_csv('submission_best_svm.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-recovery",
   "metadata": {},
   "source": [
    "SVC показал себя не лучше логрегрессии, но работает медленно.\n",
    "\n",
    "Говорят, что решающие деревья хорошо подходят для подобных задач.\n",
    "\n",
    "Попробуем их, но не просто в виде решающих деревьев, а с бустингом.\n",
    "\n",
    "# 6. XGBoost и Catboost\n",
    "## 6.1. XGBoost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_factor = (len(y_train) - sum(y_train))/(sum(y_train)) #пока сбалансируем классы так\n",
    "xg = xgb.XGBClassifier(max_depth = 3, max_bin = 1000, scale_pos_weight = balance_factor, eval_metric = 'auc')\n",
    "xg.fit(X_train, y_train)\n",
    "results = results.append(construct_metrics('XG Boost', xg, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-glass",
   "metadata": {},
   "source": [
    "ROC AUC получилась относительно хорошая, f1 - примерно как раньше. Попробуем подобрать максимальное количество деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = xgb.DMatrix(X_train, label=y_train)\n",
    "xg = xgb.XGBClassifier(missing=9999999999,\n",
    "                    max_depth = 7,\n",
    "                    n_estimators=700,\n",
    "                    learning_rate=0.1, \n",
    "                    nthread=8,\n",
    "                    subsample=1.0,\n",
    "                    colsample_bytree=0.5,\n",
    "                    min_child_weight = 3,\n",
    "                    seed=42,\n",
    "                    scale_pos_weight = balance_factor, \n",
    "                    eval_metric = 'auc')\n",
    "xgb_param = xg.get_xgb_params()\n",
    "cvresult = xgb.cv(xgb_param, matr, num_boost_round=5000, nfold=15, metrics=['auc'],\n",
    "     early_stopping_rounds=50, stratified=True, seed=42)\n",
    "print('Best number of trees = {}'.format(cvresult.shape[0]))\n",
    "\n",
    "xg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "xg.fit(X_train, y_train)\n",
    "results = results.append(construct_metrics('XG Boost with optimiezed number of trees', xg, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-circuit",
   "metadata": {},
   "source": [
    "Прекрасно, пока что лучший результат. Обучим xgboost на всем доступном трейне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = xgb.DMatrix(train_features, label=train['default'].values)\n",
    "xg.fit(train_features,train['default'].values)\n",
    "pd.DataFrame({'client_id':test.client_id.values, \n",
    "              'default':xg.predict_proba(test_features)[:,1]})\\\n",
    "              .to_csv('submission_xgboost.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-government",
   "metadata": {},
   "source": [
    "## 6.2. Catboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, cv, Pool\n",
    "balance_factor = (len(y_train) - sum(y_train))/(sum(y_train))\n",
    "catboost = CatBoostClassifier(task_type = 'CPU', \n",
    "                              verbose = False, \n",
    "                              class_weights = [1, balance_factor])\n",
    "catboost.fit(X_train, y_train)\n",
    "results = results.append(construct_metrics('catBoost default', catboost, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-confusion",
   "metadata": {},
   "source": [
    "Оптимизируем гиперапараметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = CatBoostClassifier(task_type = 'CPU', \n",
    "                              verbose = False, \n",
    "                              class_weights = [1, balance_factor])\n",
    "grid = {'learning_rate': [0.03, 0.1],\n",
    "        'depth': [4, 6, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "\n",
    "grid_search_result = catboost.grid_search(grid, \n",
    "                                       X=X_train, \n",
    "                                       y=y_train, \n",
    "                                       plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.append(construct_metrics('catBoost depth cv optimized', catboost, X_test, y_test))\n",
    "results.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-safety",
   "metadata": {},
   "source": [
    "Примем это за финальный результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost.fit(train_features,train['default'].values)\n",
    "pd.DataFrame({'client_id':test.client_id.values, 'default':catboost.predict_proba(test_features)[:,1]}).to_csv('submission_catboost.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-argument",
   "metadata": {},
   "source": [
    "# 7. Выводы.\n",
    "Из рассмотренных методов классификации наименее эффективными оказались методы наивного байесовского классификатора и kNN.\n",
    "Эффективность логистичесокй регрессии и методов, основанных на деревьях и бустинге, в данной задаче показывают похожий результат.\n",
    "Очень важно понимание о сбалансированности классов или об их пропорции.\n",
    "Метрика ROC AUC, как и все остальные, не может быть единственной метрикой качества модели. Необходимо рассматривать комплекс метрик (ROC AUC + precision + recall + f1 score и т.д.)\n",
    "Кросс-валидация позволяет настроить гиперпараметры для оптимального решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by = 'F1', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by = 'ROC AUC', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
